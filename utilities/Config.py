
RESULT_DIR = RESULT_DIR = '/Users/vince/ThesisDoc/Projects/Reinforcement_learning/Mygithub_repos/Arctic-Deep-Reinforcement-Learning-Benchmark/test/Data_and_graphs'


# hyperparameters = {

#     "HRL": {
#         "linear_hidden_units": linear_hidden_units,
#         "learning_rate": learning_rate,
#         "buffer_size": buffer_size,
#         "batch_size": batch_size,
#         "final_layer_activation": "None",
#         "columns_of_data_to_be_embedded": [0],
#         "embedding_dimensions": [[config.environment.observation_space.n, embedding_dimensionality]],
#         "batch_norm": batch_norm,
#         "gradient_clipping_norm": gradient_clipping_norm,
#         "update_every_n_steps": update_every_n_steps,
#         "epsilon_decay_rate_denominator": epsilon_decay_rate_denominator,
#         "discount_rate": discount_rate,
#         "learning_iterations": learning_iterations,
#         "tau": tau,
#         "sequitur_k": sequitur_k,
#         "action_length_reward_bonus": action_length_reward_bonus,
#         "pre_training_learning_iterations_multiplier": pre_training_learning_iterations_multiplier,
#         "episodes_to_run_with_no_exploration": episodes_to_run_with_no_exploration,
#         "action_balanced_replay_buffer": action_balanced_replay_buffer,
#         "copy_over_hidden_layers": copy_over_hidden_layers,
#         "use_global_list_of_best_performing_actions": use_global_list_of_best_performing_actions,
#         "keep_previous_output_layer": keep_previous_output_layer,
#         "random_episodes_to_run": random_episodes_to_run,
#         "only_train_new_actions": only_train_new_actions,
#         "only_train_final_layer": only_train_final_layer,
#         "num_top_results_to_use": num_top_results_to_use,
#         "action_frequency_required_in_top_results": action_frequency_required_in_top_results,
#         "reduce_macro_action_appearance_cutoff_throughout_training": reduce_macro_action_appearance_cutoff_throughout_training,
#         "add_1_macro_action_at_a_time": add_1_macro_action_at_a_time,
#         "calculate_q_values_as_increments": calculate_q_values_as_increments,
#         "min_num_episodes_to_play": min_num_episodes_to_play,
#         "increase_batch_size_with_actions": increase_batch_size_with_actions
#     },
# }